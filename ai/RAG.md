
## RAG
1. 为什么需要

2. 与长上下文对比

3. rag挑战
> - 企业数据复杂多样，如何处理
> - 如何构建知识库（分块与高校索引）
> - 用户问题的多样
> - 如何高效检索到问题相关信息
> - 如何排序相关信息，如何写合适的prompt激发LLM，选择哪个LLM
> - 如何评价RAG符合企业要求
> 
## LLM
> 文字接龙，概率最大的，有随机性
> 
> token，分词（如BPE分词算法）
> 
> 技术：transformer：self-Attention(multi-head-attention)每个token与其他token之间的关系
> 
> - 预训练模型
> - SFT 指令微调
> - RLHF 基于人类反馈的强化学习
> 
> AI三大马车
> - 算法
> - 数据
> - 算力
> 
> 大模型推理过程
> 加载分词算法 ==> 加载模型参数 ==> 推理生成答案
> 
> 通过GPU调用本地大模型
> 设置使用的GPU
> 加载分词器tokenizer
> 加载模型
> 推理
> 
> 通过CPU调用大模型 ollama工具
> - 底层使用llama.cpp对cpu计算做了优化
> - 支持cpu、gpu
> 
> 通过AI厂商API调用大模型
> 注册 ==> 创建应用和key ==> 接口调用

### 大模型的好坏 
1. 模型大小对模型能力的影响
> 涌现能力，小模型中没有，但是在大模型中出现的能力
> 
> 某些prompt策略对小模型失效，但是对大模型起效
> 
> 模型参数越大越好，10B简单任务，100B复杂任务
> 
2. 评测大模型
> 评测：
> - 对什么能力进行评测
> - 用什么数据进行评测
> - 评测的依据是什么
> 
> 常见评测机构：
> - MMLU
> - OpenCompass司南
> - flagEval

3. rag需要的LLM能力
- 信息抽取能力（在向量库检索的答案中获取到最有价值的信息）
- 上下文的阅读理解能力（理解上下文问题，并生成答案）
- 工具调用和function call能力（可能会调用其他工具）

4. 挑选LLM
- 模型大小选择
- 模型能力测试
- 成本和设备
- 企业数据安全

### 实操
控制随机性的参数
- 温度（Temperature）
  - >1 概率大的变小，反之变大
  - =1 概率不变
  - <1 概率大的会更大
- Top-K 输出在top-k的范围里随机选择一个，k越大范围越大生成的本文越多样；k = 1就直接选择概率最高的token 
- Top-p 累积概率来限定范围，选择的token是动态的；top-p=0.5表示范围是概率在前50%的tokens 
- max-tokens 模型在停止生成之前可以生成的最大token数量